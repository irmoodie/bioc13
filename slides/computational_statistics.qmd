---
title: "Computational statistics"
draft: false
date: 2025-04-25
subtitle: "Lecture 2"
---

# Review {background-color="#61599d"}

```{r}
#| echo: false
#| warning: false
#| eval: true
library(tidyverse, quietly = TRUE)
library(infer, quietly = TRUE)
library(patchwork, quietly = TRUE)

theme_set(cowplot::theme_cowplot(font_family = "Atkinson Hyperlegible") + theme(aspect.ratio = 1, legend.position = "none"))

set.seed(123)
dataset_name <- tibble(
  variable_1 = c(rnorm(20, mean = 10, sd = 2), rnorm(20, mean = 11, sd = 2)),
  variable_2 = rep(c("group_a", "group_b"), each = 20)
)

tephritis_data <- read_csv("https://raw.githubusercontent.com/irmoodie/teaching_datasets/refs/heads/main/tephritis_phenotype_clean/tephritis_phenotype.csv")
```

## Review
### Populations and Samples

![](images/pop_samp_stat.svg){fig-align="center"}

## Review
### Populations and Samples

```{r}
#| echo: true
#| eval: false
tephritis_data
```

```{r}
#| echo: false
#| eval: true
head(tephritis_data) |> knitr::kable()
```

## Review
### Populations and Samples
```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
set.seed(123)
ggplot( 
  data = tephritis_data |> drop_na(ovipositor_length_mm),
  mapping = aes(x = host_plant, y = ovipositor_length_mm)
  ) +
  geom_jitter(alpha = 0.3, width = 0.2)
```

## Review
### Populations and Samples
```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

set.seed(123)
ggplot( 
  data = tephritis_data |> drop_na(ovipositor_length_mm),
  mapping = aes(x = host_plant, y = ovipositor_length_mm)
  ) +
  geom_boxplot(outliers = FALSE, width = 0.4) +
  geom_jitter(alpha = 0.3, width = 0.2)
```

## Review
### Populations and Samples
```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
set.seed(123)
ggplot( 
  data = tephritis_data |> drop_na(ovipositor_length_mm),
  mapping = aes(x = host_plant, y = ovipositor_length_mm)
  ) +
  geom_jitter(alpha = 0.3, width = 0.2) +
  stat_summary(fun = "mean", geom = "point", shape = 18, size = 5, color = "red")

```

## Review
### Populations and Samples
```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
set.seed(123)
ggplot( 
  data = tephritis_data |> drop_na(ovipositor_length_mm),
  mapping = aes(x = host_plant, y = ovipositor_length_mm)
  ) +
  geom_jitter(alpha = 0.3, width = 0.2) +
  stat_summary(fun = "mean", geom = "line", aes(group = 1), color = "red", linetype = "dashed") +
  stat_summary(fun = "mean", geom = "point", shape = 18, size = 5, color = "red")

```

## Review
### Research question

- Do flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant` differ in their `ovipositor_length_mm`?

## Review
### Observed statistic

```{r}
#| echo: true
#| eval: true
#| warning: false
obs_stat <-
  tephritis_data |> 
  specify(response = ovipositor_length_mm, explanatory = host_plant) |> 
  calculate(stat = "diff in means", order = c("heterophyllum", "oleraceum"))

obs_stat
```

- Was this just luck? What would happen if I measured another 600 flies?

## Review 
### The sampling distribution

![](images/pop_samplingdist.svg){fig-align="center" fig-align="middle"}

## Review 
### The sampling distribution

- Problem: we (usually) only collect one sample

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

obs_stat |> ggplot(aes(x = stat)) + geom_histogram(binwidth = 0.05, bins = 30) +xlim(c(-0.5, 0.5)) + xlab("Diff in means")
```


## Review 
### The sampling distribution

- Problem: we (usually) only collect one sample
- One (of many) solutions: resample our sample (*with replacement*) to generate more samples
  - **Bootstrap** resampling 
  - Assumes that our sample is representative of the population!

## Review 
### The bootstrap sampling distibution

![](images/bootstrap.svg){fig-align="center"}

## Review 
### The bootstrap sampling distibution

Example in R for a difference in means:

```{r}
#| echo: true
#| eval: true
#| warning: false

library(infer)

boot_dist <-
  tephritis_data |> #<1>
  specify(response = ovipositor_length_mm, explanatory = host_plant) |> #<2>
  generate(reps = 10000, type = "bootstrap") |> #<3>
  calculate(stat = "diff in means", order = c("heterophyllum", "oleraceum")) #<4>
```
1. Name of the dataset we are working with.
2. `specify` which variables we are interested in.
3. `generate` new samples with bootstrap resampling.
4. `calculate` the chosen statistic for each new sample generated.

## Review 
### The bootstrap sampling distibution

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
visualize(boot_dist)
```

## Review
### Research question

- Do flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant` differ in their `ovipositor_length_mm`?

```{r}
#| echo: true
#| eval: true
obs_stat
```

- What would happen if we sampled again?

## Review
### Confidence intervals

![](images/CI.svg){fig-align="center"}

## Review
### Confidence intervals

- If we collected another sample of the same size, how much would our test statistic be likely to vary?
- **Percentile method** 
  - middle X% of sampling distribution

## Review
### Confidence intervals

Example in  R:

```{r}
#| echo: true
#| eval: true
percentile_ci <-
  boot_dist |> #<1>
  get_confidence_interval(level = 0.95, type = "percentile") #<2>
```
1. The bootstrap sampling distribution
2. Function from `infer` to calculate a 95% CI with `"percentile"` method

```{r}
#| echo: true
#| eval: true
percentile_ci
```

## Review
### Confidence intervals

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
visualize(boot_dist) +
  shade_confidence_interval(endpoints = percentile_ci)
```


## Review
### Research question

- Do flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant` differ in their `ovipositor_length_mm`?

```{r}
#| echo: true
#| eval: true
obs_stat
```

- What would happen if we sampled again?
  - We are pretty sure the difference would be between:

```{r}
#| echo: true
#| eval: true
percentile_ci
```

## Review
### Research question

- Do flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant` differ in their `ovipositor_length_mm`?
  - Observed difference in means: 0.108
  - 95% confidence interval: 0.074 - 0.141

## Review
### Research question

- Do flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant` differ in their `ovipositor_length_mm`?
  - Observed difference in means: 0.108
  - 95% confidence interval: 0.074 - 0.141


- Could we have observed this if there was truly no difference?

## Review
### Hypothesis testing

![](images/hyptest.svg){fig-align="center"}

## Review
### Hypothesis testing

- Null hypothesis
  - There is no difference in `ovipositor_length_mm` between flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant`.


- Alternative hypothesis
  - There is difference in `ovipositor_length_mm` between flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant`.

## Review
### Hypothesis testing

- Null hypothesis
  - There is no difference in `ovipositor_length_mm` between flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant`.
- We test to see if our sample allows us to **reject the null hypothesis** with sufficient confidence.

## Review
### Hypothesis testing

- Need to know what sort of differences we could observe **if** the null hypothesis was true
- Need to generate a **null distribution** which we will then compare our **observed statistic** against.

## Review
### Hypothesis testing

![](images/hyptest.svg){fig-align="center"}

## Review
### Hypothesis testing

- If null hypothesis is true:
  - `host_plant` variable has *no* predictive value for `ovipositor_length_mm`
  - Randomly shuffling (**permuting**) `host_plant` should produce samples *similar* to observed sample
- If null hypothesis is false:
  - `host_plant` variable has predictive value for `ovipositor_length_mm`
  - Randomly shuffling (**permuting**) `host_plant` should produce samples *different* to observed sample

## Review
### Hypothesis testing

```{r}
#| echo: true
#| eval: true
#| warning: false

null_dist <-
  tephritis_data |> 
  specify(response = ovipositor_length_mm, explanatory = host_plant) |>
  hypothesise(null = "independence") |> #<1>
  generate(reps = 10000, type = "permute") |> #<2>
  calculate(stat = "diff in means", order = c("heterophyllum", "oleraceum"))
```
1. We declare our null hypothesis to be that the `response` and `explanatory` variables are independent of each other.
2. We generate 10000 permutated datasets under this hypothesis, and calculate the statistic for each dataset

## Review
### Hypothesis testing

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
visualize(null_dist)
```

## Review
### Hypothesis testing

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
visualize(null_dist) +
  shade_p_value(obs_stat, direction = "both")
```

## Review
### Hypothesis testing

```{r}
#| echo: true
#| eval: true
null_dist |>
  get_p_value(obs_stat, direction = "both")
```

## Review
### Research question

- Do flies that use `"heterophyllum"` as a `host_plant` and flies that use `"oleraceum"` as a `host_plant` differ in their `ovipositor_length_mm`?
  - Observed difference in means: 0.108
  - 95% confidence interval: 0.074 - 0.141
- Could we have observed this if there was truly no difference?
  - Very unlikely (p < 0.0001)

# How to address other research questions {background-color="#61599d"}

## Other research questions
### Already covered

- Difference between two groups in a continuous variable
  - Difference in means
  - Can be applied to any other difference

## Other research questions
### Today

- Does an observed statistic differ from a hypothesised value?
  - Continuous variable (mean, median, sd, etc)
  - Categorical varaible (proportion)
- Difference between >2 groups in a continuous variable
- Are two (or more) distributions different?
- Is there a linear relationship between two variables?
- Do two groups differ in their relationship between two variables?

# Difference between >2 groups in a continuous variable {background-color="#61599d"}

## Comparing means between >2 groups
### Analysis of Variance (ANOVA)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
tephritis_data_edit <- tephritis_data |>
  bind_rows(
    tephritis_data |>
      filter(host_plant == "heterophyllum") |>
      mutate(
        host_plant = "imaginophyllum",
        ovipositor_length_mm = ovipositor_length_mm - 0.2 + rnorm(n(), mean = 0, sd = 0.05)
      )
  )

tephritis_data |>
  ggplot(aes(x = ovipositor_length_mm, fill = host_plant)) +
  geom_density(colour = "white", alpha = 0.4) +
  theme(legend.position = "top")
```

## Comparing means between >2 groups
### Analysis of Variance (ANOVA)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

tephritis_data_edit2 <- tephritis_data |> drop_na(ovipositor_length_mm) |>
  mutate(
    ovipositor_length_mm = if_else(
      host_plant == "oleraceum",
      ovipositor_length_mm - (mean(ovipositor_length_mm[host_plant == "oleraceum"]) - mean(ovipositor_length_mm[host_plant == "heterophyllum"])),
      ovipositor_length_mm
    )
  )

tephritis_data_edit2 |>
  ggplot(aes(x = ovipositor_length_mm, fill = host_plant)) +
  geom_density(colour = "white", alpha = 0.4) +
  theme(legend.position = "top")
```

## Comparing means between >2 groups
### Analysis of Variance (ANOVA)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

tephritis_data_edit |>
  ggplot(aes(x = ovipositor_length_mm, fill = host_plant)) +
  geom_density(colour = "white", alpha = 0.4) +
  theme(legend.position = "top")
```

## Comparing means between >2 groups
### The ratio of variances (F-statistic)

$$
F = \frac{\text{Variance 1}}{\text{Variance 2}}
$$

- Can (in general) be used to test if the variances are equal between sources of variance
  - $F=1$ if variances are equal
  - $F$ is very low if variance 1 < variance 2
  - $F$ is very high if variance 1 > variance 2

## Comparing means between >2 groups
### Analysis of Variance (ANOVA)

$$
F = \frac{\text{Mean variance between-group}}{\text{Mean variance within-group}}
$$

- If $F$ is very big, more likely that means are different

## Comparing means between >2 groups
### Analysis of Variance (ANOVA)

- If you want to know if >2 groups differ in their means, use F-statistic
- Null hypothesis
  - The means of all groups are the same
  - Mean A == Mean B == Mean C
- Alternative hypothesis
  - The means of at least one group differ from the global mean

## Comparing means between >2 groups
### Analysis of Variance (ANOVA)

![](images/hyptest.svg){fig-align="center"}

# Different from a hypothesised value? {background-color="#61599d"}

## Different from a hypothesised value?
### Continuous variable

- Is the mean `ovipositor_length_mm` in the `heterophyllum` host race different from 1.78 mm?
- Confidence interval approach
- Hypothesis testing approach

## Different from a hypothesised value?
### Continuous variable

Observed difference:

```{r}
#| echo: true
#| eval: true
het_data <-
  tephritis_data |> 
  filter(host_plant == "heterophyllum" & sex == "female")

obs_stat <-
  het_data |>
  specify(response = ovipositor_length_mm) |>
  calculate(stat = "mean")

obs_stat
```

## Different from a hypothesised value?
### Continuous variable (confidence interval approach)

![](images/CI.svg){fig-align="center"}

## Different from a hypothesised value?
### Continuous variable (confidence interval approach)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

boot_dist <-
  het_data |>
  specify(response = ovipositor_length_mm) |>
  generate(reps = 10000, type = "bootstrap") |>
  calculate(stat = "mean")

visualise(boot_dist)
```


## Different from a hypothesised value?
### Continuous variable (confidence interval approach)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
conf_int <-
  boot_dist |>
  get_confidence_interval(level = 0.95, type = "percentile")

visualise(boot_dist) +
  shade_confidence_interval(endpoints = conf_int)
```

## Different from a hypothesised value?
### Continuous variable (confidence interval approach)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

visualise(boot_dist) +
  shade_confidence_interval(endpoints = conf_int) +
  geom_vline(xintercept = 1.78, colour = "red")
```

## Different from a hypothesised value?
### Continuous variable (confidence interval approach)

- Is the mean `ovipositor_length_mm` in the `heterophyllum` host race different from 1.78 mm?
  - Observed: 1.764 mm
  - 95% confidence interval: 1.74 - 1.79 mm
  - True mean is likely in this range
  - Hypothesised value (1.78 mm) is also in the range
  - We are not so confident that the true mean is not 1.78 mm

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

![](images/hyptest.svg){fig-align="center"}

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

- Is the mean `ovipositor_length_mm` in the `heterophyllum` host race different from 1.78 mm?

{{< countdown minutes=1.5 top=0 right=0 font-size="5rem" >}}

::: {.callout-important icon="false"}
## Think 30 sec, discuss 60 sec
What is our null and alternative hypothesis?
:::

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

- How do we get a null distribution?
  - Permuting is not an option here

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

het_data |>
ggplot(aes(x = ovipositor_length_mm)) +
geom_density(fill = "grey70", colour = "white") +
geom_vline(xintercept = 1.764345) +
labs(title = "Sample distribution (not sampling distribution!)") +
xlim(1.3, 2.25) +
theme(aspect.ratio = 0.5, axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

het_data |>
ggplot(aes(x = ovipositor_length_mm)) +
geom_density(fill = "grey70", colour = "white") +
geom_vline(xintercept = 1.764345) +
geom_vline(xintercept = 1.78, colour = "red") +
labs(title = "Sample distribution (not sampling distribution!)") +
xlim(1.3, 2.25) +
theme(aspect.ratio = 0.5, axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

het_data |>
ggplot(aes(x = ovipositor_length_mm)) +
geom_density(fill = "grey70", colour = "white") +
geom_density(aes(x = ovipositor_length_mm+0.015655), fill = "red", colour = "white", alpha = 0.3) +
geom_vline(xintercept = 1.764345) +
geom_vline(xintercept = 1.78, colour = "red") +
labs(title = "Sample distribution (not sampling distribution!)") +
xlim(1.3, 2.25) +
theme(aspect.ratio = 0.5, axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

![](images/hyptest.svg){fig-align="center"}

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

- Bootstrap resample from our new dataset that is compatible with the null hypothesis

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

set.seed(123)
null_dist <-
  het_data |>
  specify(response = ovipositor_length_mm) |>
  hypothesise(null = "point", mu = 1.78) |>
  generate(reps = 10000, type = "bootstrap") |>
  calculate(stat = "mean")
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

- Bootstrap resample from our new dataset that is compatible with the null hypothesis

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

visualise(null_dist)
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

- Compare with observed value

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

visualise(null_dist) +
  shade_p_value(obs_stat, direction = "both")
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

null_dist |> get_p_value(obs_stat, direction = "both")
```

## Different from a hypothesised value?
### Continuous variable (hypothesis testing approach)

- Is the mean `ovipositor_length_mm` in the `heterophyllum` host race different from 1.78 mm?
  - Observed: 1.764 mm
  - If the true mean was 1.78 mm, probability to observe 1.764 mm or a value more extreme is 0.2 (20% chance)

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

visualise(null_dist) +
  shade_p_value(obs_stat, direction = "both")
```

# Categorical data {background-color="#61599d"}

# Tests of proportion {background-color="#61599d"}

## Tests of proportion
### Is a proportion different from a hypothesised value?

- In Sweden, 58% prefer dogs (according to a survey of 2000 people by Folksam)
- Do our preferences differ from this?
  - Does the proportion of biology students who prefer dogs differ from 0.58?

```{r}
#| echo: false
#| eval: true
animal_pref <- tibble(preference = sample(c(rep("dog", 14), rep("cat", 11))))

animal_pref_se <- tibble(preference = sample(c(rep("dog", 2000/100*58), rep("cat", 2000/100*(100-58)))))
```

## Tests of proportion
### Is a proportion different from a hypothesised value?

```{r}
#| echo: false
#| eval: true
#| fig-align: center
pref_bioc13 <-
  animal_pref |>
  ggplot(aes(x = preference)) +
  geom_bar() +
  labs(title = "BIOC13: Cat vs Dog")

pref_bioc13
```

## Tests of proportion
### Is a proportion different from a hypothesised value?

Calculate the test statistic:

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

obs_stat <- 
  animal_pref |>
  specify(response = preference, success = "dog") |>
  calculate(stat = "prop")

obs_stat
```

## Tests of proportion
### Is a proportion different from a hypothesised value? (CI)

![](images/CI.svg){fig-align="center"}

## Tests of proportion
### Is a proportion different from a hypothesised value? (CI)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

boot_dist <-
  animal_pref |>
  specify(response = preference, success = "dog") |>
  generate(reps = 10000, type = "bootstrap") |>
  calculate(stat = "prop")

visualise(boot_dist)
```

## Tests of proportion
### Is a proportion different from a hypothesised value? (CI)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
conf_int <-
  boot_dist |>
  get_confidence_interval(level = 0.95, type = "percentile")

visualise(boot_dist) +
  shade_confidence_interval(endpoints = conf_int)
```

## Tests of proportion
### Is a proportion different from a hypothesised value? (Hyp. test)

![](images/hyptest.svg){fig-align="center"}

## Tests of proportion
### Is a proportion different from a hypothesised value? (Hyp. test)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

null_dist <-
  animal_pref |>
  specify(response = preference, success = "dog") |>
  hypothesize(null = "point", p = 0.58) |>
  generate(reps = 10000, type = "draw") |>
  calculate(stat = "prop")

visualise(null_dist)
```

## Tests of proportion
### Is a proportion different from a hypothesised value? (Hyp. test)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

visualise(null_dist) +
  shade_p_value(obs_stat = obs_stat, direction = "two-sided")
```

## Tests of proportion
### Is a proportion different from a hypothesised value? (Hyp. test)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10

null_dist |>
  get_p_value(obs_stat = obs_stat, direction = "two-sided")
```

# Tests of proportion, but more {background-color="#61599d"}

# Are 2 or more distributions different? {background-color="#61599d"}

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

- Exactly what we have just done, but we extend it beyond binary (yes/no, cat/dog) data
- Similar to how F-statistic allows for diff in means for many groups
- $\chi^2$ allows for difference in proportions for many categories

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

![](images/mendel.jpg){fig-align="center"}

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

```{r}
#| echo: false
#| eval: true

# Generate expected data under Mendelian laws for a dihybrid cross
set.seed(123) # For reproducibility

# Define expected proportions for a dihybrid cross (9:3:3:1 ratio)
expected_proportions <- c(8.7, 2.5, 3.5, 1.3) / 16

# Generate a dataset with 160 observations (to match proportions)
mendelian_data <- tibble(
  phenotype = rep(c("A-B-", "A-bb", "aaB-", "aabb"), times = round(expected_proportions * 120))
)
```

```{r}
#| echo: false
#| eval: true
mendelian_data
```

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
ggplot(mendelian_data, aes(x = phenotype)) +
  geom_bar() +
  geom_hline(yintercept = c(9, 3, 1)/16*nrow(mendelian_data), linetype = "dashed", color = "red")
```

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

$$
\chi^2 = \sum \frac{(Observed_i - Expected_i)^2}{Expected_i}
$$

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

![](images/hyptest.svg){fig-align="center"}

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
obs_stat <- 
  mendelian_data |>
  specify(response = phenotype) |>
  hypothesize(
    null = "point",
    p = c(
      "A-B-" = 9/16,
      "A-bb" = 3/16,
      "aaB-" = 3/16,
      "aabb" = 1/16
    )
   ) |>
  calculate(stat = "Chisq")
```

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

- Null hypothesis:
  - The sample came from the hypothesised distribution
  - The sample distribution is not different from the hypothesised distribution
- Alternative hypotheis:
  - The sample came from a different distribution to the one hypothesised
  - The sample distribution is different from the hypothesised distribution


## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
null_dist <- 
  mendelian_data |>
  specify(response = phenotype) |>
  hypothesize(
    null = "point",
    p = c(
      "A-B-" = 9/16,
      "A-bb" = 3/16,
      "aaB-" = 3/16,
      "aabb" = 1/16
    )
   ) |>
  generate(reps = 10000, type = "draw") |>
  calculate(stat = "Chisq")
```

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
null_dist |>
  visualize() + 
  shade_p_value(obs_stat, direction = "greater")
```

## $\chi^2$ Goodness of fit
### Does the observed data differ from an expected distribution?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
null_dist |>
  get_p_value(obs_stat = obs_stat, direction = "greater")
```

# Are two categorical variables associated with each other? {background-color="#61599d"}

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
germ_data <- tibble(
  treatment = rep(c("coating_a", "coating_b", "coating_c", "control"), each = 30),
  germination_success = c(
    sample(c("germinated", "failed_to_germinate"), size = 30, replace = TRUE, prob = c(0.70, 0.30)),
    sample(c("germinated", "failed_to_germinate"), size = 30, replace = TRUE, prob = c(0.72, 0.28)),
    sample(c("germinated", "failed_to_germinate"), size = 30, replace = TRUE, prob = c(0.65, 0.35)),
    sample(c("germinated", "failed_to_germinate"), size = 30, replace = TRUE, prob = c(0.68, 0.30))
  )
)
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
germ_data |>
  ggplot(aes(x = treatment, fill = germination_success)) +
  geom_bar(position = "fill") +
  ylab("Proportion") +
  theme(legend.position = "right")
```

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
germ_data
```

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

- Null hypothesis:
  - The two categorical variables are not associated with each other
  - The two categorical variables are independent
- Alternative hypothesis:
  - The two categorical variables are associated with each other
  - The two categorical variables are not independent

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

![](images/hyptest.svg){fig-align="center"}

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
obs_stat <- 
  germ_data |>
  specify(response = germination_success, explanatory = treatment) |>
  calculate(stat = "Chisq")

obs_stat
```


## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
null_dist <- 
  germ_data |>
  specify(response = germination_success, explanatory = treatment) |>
  hypothesize(null = "independence") |>
  generate(reps = 10000, type = "permute") |>
  calculate(stat = "Chisq")
```

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
visualize(null_dist) +
  shade_p_value(obs_stat, direction = "greater")
```

## $\chi^2$ Test of independence
### Are two categorical variables associated with each other?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
null_dist |>
  get_p_value(obs_stat = obs_stat, direction = "greater")
```

# Correlation {background-color="#61599d"}

## Correlation
### Do two continuous variables covary?

- Used to assess if two continuous variables are independent, or if they covary (linearly)
- We do not express one variable as a function of another:
  - No "response" and "explanatory"
- Usually assumed that both variables are "effects of a common cause" [@sokal1995]
- "Correlation does not mean causation"
  - But you can measure a correlation between a cause and effect


## Correlation
### Do two continuous variables covary?

Correlation coefficient (Pearson):

$$
r = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2} \sqrt{\sum_{i=1}^n (y_i - \bar{y})^2}}
$$

$$
r = \frac{\text{Covariance}(x,y)}{\text{Standard deviation}(x) \times \text{Standard deviation}(y)}
$$

$$
r = \frac{\text{Cov}(x,y)}{\sigma_x \sigma_y}
$$

## Correlation
### Do two continuous variables covary?

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
set.seed(122)
data <- tibble(
  x = rnorm(100, mean = 50, sd = 10),
  y = x + rnorm(100, mean = 0, sd = 5)
) |>
mutate(y = mean(y) - 0.3*(mean(y) - y))


scatterplot <-
data |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.5, size = 3) +
  lims(x = c(20,80), y = c(20,80))

x_plot <-
data |>
  ggplot(aes(x = x, y = "1")) +
  geom_jitter(height = 0, alpha = 0.2, size = 3) +
  geom_vline(aes(xintercept = mean(x)), color = "red", linetype = "dashed") +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.line.y = element_blank()
  ) +
  lims(x = c(20,80))

y_plot <-
data |>
  ggplot(aes(x = "1", y = y)) +
  geom_jitter(width = 0, alpha = 0.2, size = 3) +
  geom_hline(aes(yintercept = mean(y)), color = "red", linetype = "dashed") +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.line.x = element_blank()
  ) +
  lims(y = c(20,80))

```

::: {.columns}
::: {.column}
$$
r = \frac{\text{Cov}(x,y)}{\sigma_x \sigma_y}
$$
:::
::: {.column}
```{r}
#| echo: false
#| eval: true
scatterplot
```
:::
:::

## Correlation
### Do two continuous variables covary?

::: {.columns}
::: {.column}
$$
r = \frac{\text{Cov}(x,y)}{\sigma_x \sigma_y}
$$

Calculate standard deviation in $x$:

$$
\sigma_x = \sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}
$$

```{r}
#| echo: true
#| eval: true
data |>
  observe(response = x, stat = "sd")
```

:::
::: {.column}
```{r}
#| echo: false
#| eval: true
x_plot
```
:::
:::

## Correlation
### Do two continuous variables covary?

::: {.columns}
::: {.column}
$$
r = \frac{\text{Cov}(x,y)}{\sigma_x \sigma_y}
$$

Calculate standard deviation in $y$:

$$
\sigma_y = \sqrt{\sum_{i=1}^n (y_i - \bar{y})^2}
$$

```{r}
#| echo: true
#| eval: true
data |>
  observe(response = y, stat = "sd")
```

:::
::: {.column}
```{r}
#| echo: false
#| eval: true
y_plot
```
:::
:::

## Correlation
### Do two continuous variables covary?

::: {.columns}
::: {.column}
$$
r = \frac{\text{Cov}(x,y)}{\sigma_x \sigma_y}
$$

Calculate the covariance between $x$ and $y$:

$$
Cov(x,y) = \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})
$$

```{r}
#| echo: true
#| eval: true
data |>
  cov()
```
:::
::: {.column}
```{r}
#| echo: false
#| eval: true
scatterplot + 
geom_hline(aes(yintercept = mean(y)), color = "red", linetype = "dashed") +
geom_vline(aes(xintercept = mean(x)), color = "red", linetype = "dashed")
```
:::
:::

## Correlation
### Do two continuous variables covary?

::: {.columns}
::: {.column}
$$
r = \frac{\text{Cov}(x,y)}{\sigma_x \sigma_y}
$$

```{r}
#| echo: true
#| eval: true
data |>
  specify(x ~ y) |>
  calculate(stat = "correlation")
```
:::
::: {.column}
```{r}
#| echo: false
#| eval: true
scatterplot
```
:::
:::

## Correlation
### Do two continuous variables covary?

![](images/cor.svg){fig-align="center"}

## Correlation
### Do two continuous variables covary?

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
#| warning: false

tephritis_data |>
  ggplot(aes(x = body_length_mm, y = ovipositor_length_mm)) +
  geom_point(size = 3, alpha = 0.7)
```

## Correlation
### Do two continuous variables covary?

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
#| warning: false
obs_stat <-
  tephritis_data |>
  specify(ovipositor_length_mm ~ body_length_mm) |>
  calculate(stat = "correlation")

obs_stat
```

## Correlation
### Do two continuous variables covary? (CI)

![](images/CI.svg){fig-align="center"}

## Correlation
### Do two continuous variables covary? (CI)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
#| warning: false
boot_dist <-
  tephritis_data |>
  specify(ovipositor_length_mm ~ body_length_mm) |>
  generate(reps = 10000, type = "bootstrap") |>
  calculate(stat = "correlation")

visualise(boot_dist)
```

## Correlation
### Do two continuous variables covary? (CI)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
#| warning: false
conf_int <- 
  boot_dist |>
  get_confidence_interval(level = 0.95, type = "percentile")

visualise(boot_dist) +
  shade_confidence_interval(endpoints = conf_int)
```

## Correlation
### Do two continuous variables covary? (Hyp. test)

![](images/hyptest.svg){fig-align="center"}

## Correlation
### Do two continuous variables covary? (Hyp. test)

{{< countdown minutes=2 top=0 right=0 font-size="5rem" >}}

::: {.callout-important icon="false"}
## Think 30 sec, discuss 90 sec
What is our null and alternative hypothesis? How could we generate data compatible with the null?
:::

## Correlation
### Do two continuous variables covary? (Hyp. test)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
#| warning: false
null_dist <-
  tephritis_data |>
  specify(ovipositor_length_mm ~ body_length_mm) |>
  hypothesise(null = "independence") |>
  generate(reps = 10000, type = "permute") |>
  calculate(stat = "correlation")
```

## Correlation
### Do two continuous variables covary? (Hyp. test)

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| fig-width: 10
#| warning: false
visualize(null_dist) +
  shade_p_value(obs_stat = obs_stat, direction = "both")
```

# Regression {background-color="#61599d"}

## Regression
### How does variable Y depend on variable X

- A mathmatical function describing the relationship between two continuous variables
- Y is dependant on X (the)
- Y is a function of X
- Predictive model
- Very powerful framework

## Regression
### How does variable Y depend on variable X

$$
y = \text{Slope}\times x + \text{Intercept}
$$

$$
y = mx+c
$$

$$
y = \beta_1x+\beta_0
$$

$$
y = \beta_0+\beta_1x+\beta_2x_2+\beta_3x_3+\beta_4x_4+\beta_5x_5
$$

## Regression
### How does variable Y depend on variable X

```{r}
#| fig-width: 10
# Generate a range of intercept and slope values
intercepts <- seq(-10, 10, by = 5)
slopes <- 1

# Create a grid of intercept and slope combinations
abline_data <- expand.grid(intercept = intercepts, slope = slopes)

# Generate a dataset for plotting
plot_data <- tibble(x = seq(-10, 10, length.out = 100))

# Add lines for each intercept and slope combination
abline_data <- abline_data |>
  rowwise() |>
  mutate(
    line_data = list(plot_data |> mutate(y = slope * x + intercept))
  ) |>
  unnest(line_data)

# Plot the lines
intercept_plot <-
abline_data |>
  ggplot(aes(x = x, y = y, color = as.factor(intercept))) +
  geom_line() +
  labs(
    title = "Effect of Changing Intercept",
    x = "X",
    y = "Y",
    color = "Intercept"
  ) +
  coord_cartesian(xlim = c(0, 10), expand = FALSE) +
  theme(legend.position = "left")
# Generate a range of intercept and slope values
intercepts <- 0
slopes <- seq(-5, 5, by = 2)

# Create a grid of intercept and slope combinations
abline_data <- expand.grid(intercept = intercepts, slope = slopes)

# Generate a dataset for plotting
plot_data <- tibble(x = seq(-10, 10, length.out = 100))

# Add lines for each intercept and slope combination
abline_data <- abline_data |>
  rowwise() |>
  mutate(
    line_data = list(plot_data |> mutate(y = slope * x + intercept))
  ) |>
  unnest(line_data)

# Plot the lines
slope_plot <-
abline_data |>
  ggplot(aes(x = x, y = y, color = as.factor(slope))) +
  geom_line() +
  labs(
    title = "Effect of Changing Slope",
    x = "X",
    y = "Y",
    color = "Slope"
  ) +
  coord_cartesian(xlim = c(0, 10), expand = FALSE) +
  theme(legend.position = "right")

intercept_plot + slope_plot
```

## Regression
### How does variable Y depend on variable X

```{r}
#| fig-width: 10

set.seed(123)

# Dataset 1: Strong positive correlation
data1 <- tibble(
  x = rnorm(100, mean = 50, sd = 10),
  y = x + rnorm(100, mean = 0, sd = 5)
)

# Dataset 2: Moderate positive correlation
data2 <- tibble(
  x = rnorm(100, mean = 50, sd = 10),
  y = rnorm(100, mean = 50, sd = 10)
)

# Dataset 3: Weak positive correlation
data3 <- tibble(
  x = rnorm(100, mean = 50, sd = 10),
  y = -x + rnorm(100, mean = 0, sd = 10)
)

calculate_stats <- function(data) {
  model <- lm(y ~ x, data = data)
  intercept <- coef(model)[1]
  slope <- coef(model)[2]
  paste0("Intercept = ", round(intercept, 2), ", Slope = ", round(slope, 2))
}

stats1 <- calculate_stats(data1)
stats2 <- calculate_stats(data2)
stats3 <- calculate_stats(data3)

# Combine datasets for visualization
data_combined <- bind_rows(
  data1 |> mutate(dataset = stats1),
  data2 |> mutate(dataset = stats2),
  data3 |> mutate(dataset = stats3)
)

data_combined |>
  ggplot(aes(x = x, y = y, color = dataset)) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(alpha = 0.7, size = 3) +
  facet_wrap(~dataset, scale = "free") +
  theme(
    strip.text = element_text(size = 14),
    panel.background = element_blank()
  )
```

## Regression
### How does variable Y depend on variable X

- Example: For sexual selection to operate, an increase in mating success (number of mates) must result in an increase in reproductive success (number of offspring).

```{r}
#| fig-align: center
set.seed(123)
# Generate two positively correlated variables
x <- rlnorm(100, meanlog = log(5), sdlog = log(1.5))
y <- 4 * x + rnorm(100, mean = 0, sd = 10)


# Combine into a tibble
mating_data <- tibble(x = round(x, 0), y = round(y, 0)) |> mutate(y = if_else(x < 6, y - (y - 10) * 0.2, y)) |> mutate(y = if_else(y < 0, 0, y))

# Visualize the relationship
sex_plot <-
mating_data |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.5, size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Mating success", y = "Reproductive success")

sex_plot

mating_data <- mating_data |> rename(mating_success = x, reproductive_success = y)

```

## Regression
### How does variable Y depend on variable X

::: {.columns}
::: {.column}
$$
y = \beta_1x+\beta_0
$$

$$
y = 3.83x-0.68
$$

- $\beta_1$ = strength of sexual selection
- For each additional mate, an individual (on average) gains $\beta_1$ additional offspring
- For 5 mates ($x=5$): 
  - $y = 3.83\times5-0.68$
  - $y = 18.47$
:::
::: {.column}
```{r}
sex_plot
```
:::
:::



## Regression
### How does variable Y depend on variable X

```{r}
#| fig-align: center
# Fit a linear model
data1 <- slice_sample(data1, n = 20)
# Create a second dataset with a poorly fitting line
model1 <- lm(y ~ x, data = data1)

# Add residuals and squared residuals to the first dataset
data_with_residuals1 <- data1 |>
  mutate(
    fitted = predict(model1),
    residual = y - fitted,
    squared_residual = residual^2
  )

model2 <- lm(y ~ x, data = data1)

model2$coefficients[1] <- -10
model2$coefficients[2] <- 1.3

# Add residuals and squared residuals to the second dataset
data_with_residuals2 <- data1 |>
  mutate(
    fitted = predict(model2),
    residual = y - fitted,
    squared_residual = residual^2
  )

# Plot the data with squared residuals
data_with_residuals1 |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 3) +
  geom_line(aes(y = fitted), color = "blue", linetype = "solid", linewidth = 2) +
  coord_cartesian(xlim=c(20,80), ylim=c(20,80))
  #geom_segment(aes(xend = x, yend = fitted), color = "red", alpha = 0.5) 
  #geom_point(aes(y = fitted + squared_residual), color = "purple", size = 2, alpha = 0.7) +
```

## Regression
### How does variable Y depend on variable X

```{r}
#| fig-align: center
data_with_residuals1 |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 3) +
  geom_line(aes(y = fitted), color = "blue", linetype = "solid", linewidth = 2) +
  geom_segment(aes(xend = x, yend = fitted), color = "red", alpha = 0.5) +
  coord_cartesian(xlim=c(20,80), ylim=c(20,80))
```

## Regression
### How does variable Y depend on variable X

```{r}
#| fig-align: center
data_with_residuals1 |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 3) +
  geom_line(aes(y = fitted), color = "blue", linetype = "solid", linewidth = 2) +
  geom_rect(aes(
    xmin = x - sqrt(squared_residual) / 2,
    xmax = x + sqrt(squared_residual) / 2,
    ymin = pmin(y, fitted),
    ymax = pmax(y, fitted)
  ), fill = "red", alpha = 0.3) +
  coord_cartesian(xlim=c(20,80), ylim=c(20,80))

```

## Regression
### How does variable Y depend on variable X
```{r}
#| fig-align: center
data_with_residuals2 |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 3) +
  geom_line(aes(y = fitted), color = "blue", linetype = "solid", linewidth = 2) +
  geom_rect(aes(
    xmin = x - sqrt(squared_residual) / 2,
    xmax = x + sqrt(squared_residual) / 2,
    ymin = pmin(y, fitted),
    ymax = pmax(y, fitted)
  ), fill = "red", alpha = 0.3) +
  coord_cartesian(xlim=c(20,80), ylim=c(20,80))
```

## Regression
### How does variable Y depend on variable X
::: {.columns}
::: {.column}
```{r}
data_with_residuals1 |>
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 3) +
  geom_line(aes(y = fitted), color = "blue", linetype = "solid", linewidth = 2) +
  geom_rect(aes(
    xmin = x - sqrt(squared_residual) / 2,
    xmax = x + sqrt(squared_residual) / 2,
    ymin = pmin(y, fitted),
    ymax = pmax(y, fitted)
  ), fill = "red", alpha = 0.3) +
  coord_cartesian(xlim=c(20,80), ylim=c(20,80))

```
:::
::: {.column}
- Fit by solving to minimise the sum of the squared residuals (SSR)
  - Find $\beta_1$ and $\beta_0$ that minimise the SSR
  - Called a "loss function"
  - Many approaches to do this!
:::
:::

## Regression
### How does variable Y depend on variable X

{{< video https://www.youtube.com/embed/3dhcmeOTZ_Q
    title="Regression animation"
    start="0"
    width="1050"
    aspect-ratio="16x9"
    align="center"
>}}


## Regression
### How to fit in R?

Base R:

```{r}
#| echo: true
lm(data = mating_data, reproductive_success ~ mating_success)
```

## Regression
### How to fit in R?

With `infer`:

```{r}
#| echo: true
observed_fit <-
  mating_data |>
  specify(reproductive_success ~ mating_success) |>
  fit()

observed_fit
```


## Regression
### Confidence intervals

```{r}
#| echo: true
boot_dist <-
  mating_data |>
  specify(reproductive_success ~ mating_success) |>
  generate(reps = 1000, type = "bootstrap") |>
  fit()

boot_dist
```

## Regression
### Confidence intervals

```{r}
#| echo: true
conf_ints <- 
  get_confidence_interval(
    boot_dist, 
    level = .95, 
    point_estimate = observed_fit
  )

conf_ints
```

## Regression
### Confidence intervals

```{r}
#| echo: true
visualize(boot_dist) +
  shade_confidence_interval(endpoints = conf_ints)
```

## Regression
### Hypothesis test

- Null hypothesis:
  - Slope = 0
- Alternative hypothesis:
  - Slope $\neq$ 0
  - Slope < 0
  - Slope > 0

## Regression
### Hypothesis test

```{r}
#| echo: true
null_dist <-
  mating_data |>
  specify(reproductive_success ~ mating_success) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  fit()

null_dist
```

## Regression
### Hypothesis test

```{r}
#| echo: true
visualize(null_dist) +
  shade_p_value(obs_stat = observed_fit, direction = "two-sided")
```

## Regression
### Hypothesis test

```{r}
#| echo: true
null_dist |>
  get_p_value(obs_stat = observed_fit, direction = "two-sided")
```

## Regression
### Multiple regression

$$
y = \beta_1x+\beta_0
$$

$$
y = \beta_0+\beta_1x+\beta_2x_2+\beta_3x_3+\beta_4x_4+\beta_5x_5
$$

```{r}
#| eval: false
#| echo: true

data |>
specify(reproductive_success ~ mating_success + sex + feather_colour) ...

```

## Take-away points

- Introduced two new methods of generating a null hypothesis
  - `"permute"`
  - `"draw"`
- Introduced four new statistics
  - `"F-statistic"` (compare variances to infer if means differ)
  - `"Chi-sq"` (compare distributions of categorical data)
  - `"correlation"` (do two variables covary linearly?)
  - Regression coefficients (via `fit()`)

# Exercises {background-color="#61599d"}

## References 